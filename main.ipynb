{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9cf430-2f27-4863-900f-05204d187243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"xsum_sample.csv\")\n",
    "\n",
    "input_texts = data[\"document\"].tolist()\n",
    "target_summaries = data[\"summary\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eedcd5-7cec-4e97-a2b7-89bd334294e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3246aad5-96e9-4713-bf94-a473fcde4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texts, vocab_size=5000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.idx2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.build_vocab(texts)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return nltk.word_tokenize(text.lower())\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        word_freq = Counter()\n",
    "        for text in texts:\n",
    "            tokens = self.tokenize(text)\n",
    "            word_freq.update(tokens)\n",
    "        \n",
    "        most_common = word_freq.most_common(self.vocab_size - len(self.word2idx))\n",
    "        for idx, (word, _) in enumerate(most_common, start=len(self.word2idx)):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "    def encode(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.word2idx.get(token, self.word2idx[\"<UNK>\"]) for token in tokens]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        return \" \".join([self.idx2word.get(idx, \"<UNK>\") for idx in indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba035a60-7f9e-41c4-8773-b8201bd8e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    data[\"document\"].tolist() + data[\"summary\"].tolist(),\n",
    "    vocab_size=5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f9592a-7314-4974-9d3b-52dbb5b0eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def preprocess_pair(doc, summary, tokenizer, max_len=100):\n",
    "    # Encode document\n",
    "    doc_ids = tokenizer.encode(doc)\n",
    "    doc_ids = doc_ids[:max_len]\n",
    "    doc_ids += [tokenizer.word2idx[\"<PAD>\"]] * (max_len - len(doc_ids))\n",
    "\n",
    "    # Encode summary with <SOS> and <EOS>\n",
    "    sum_ids = tokenizer.encode(summary)\n",
    "    decoder_input = [tokenizer.word2idx[\"<SOS>\"]] + sum_ids\n",
    "    decoder_target = sum_ids + [tokenizer.word2idx[\"<EOS>\"]]\n",
    "\n",
    "    decoder_input = decoder_input[:max_len]\n",
    "    decoder_target = decoder_target[:max_len]\n",
    "\n",
    "    decoder_input += [tokenizer.word2idx[\"<PAD>\"]] * (max_len - len(decoder_input))\n",
    "    decoder_target += [tokenizer.word2idx[\"<PAD>\"]] * (max_len - len(decoder_target))\n",
    "\n",
    "    return torch.tensor(doc_ids), torch.tensor(decoder_input), torch.tensor(decoder_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d793430-6e35-4dbf-ae55-f9ce10a4b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input: tensor([   4,  518,  735,    8, 1268,   11,    3, 1489,    6,   59,    8,    4,\n",
      "         633, 1406,  721])\n",
      "Decoder Input: tensor([   1,    3, 1185,   34, 1500,  267,    4,  239, 1881,   10, 2127,   10,\n",
      "        2912,   50, 1960])\n",
      "Decoder Target: tensor([   3, 1185,   34, 1500,  267,    4,  239, 1881,   10, 2127,   10, 2912,\n",
      "          50, 1960,  783])\n"
     ]
    }
   ],
   "source": [
    "doc = data[\"document\"][0]\n",
    "summary = data[\"summary\"][0]\n",
    "\n",
    "enc_in, dec_in, dec_out = preprocess_pair(doc, summary, tokenizer)\n",
    "\n",
    "print(\"Encoder Input:\", enc_in[:15])\n",
    "print(\"Decoder Input:\", dec_in[:15])\n",
    "print(\"Decoder Target:\", dec_out[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a969f2-a23c-40c4-a911-d9278a640f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e185d767-1f68-4184-bbec-c5ea05c03218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden, cell):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565c4660-f048-4888-934e-aff9e94a3b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "vocab_size = len(tokenizer.word2idx)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model Initialization\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.word2idx[\"<PAD>\"])\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabeca76-c872-4be0-ab90-5c5a24bd5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_step(encoder, decoder, data, tokenizer, encoder_optimizer, decoder_optimizer, criterion, device):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        doc = data[\"document\"][i]\n",
    "        summary = data[\"summary\"][i]\n",
    "\n",
    "        # Preprocess inputs\n",
    "        enc_in, dec_in, dec_out = preprocess_pair(doc, summary, tokenizer)\n",
    "        enc_in = enc_in.unsqueeze(0).to(device)       # shape: (1, seq_len)\n",
    "        dec_in = dec_in.unsqueeze(0).to(device)\n",
    "        dec_out = dec_out.unsqueeze(0).to(device)\n",
    "\n",
    "        # Reset gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through encoder\n",
    "        _, hidden, cell = encoder(enc_in)\n",
    "\n",
    "        # Decoder forward pass\n",
    "        output, _, _ = decoder(dec_in, hidden, cell)\n",
    "\n",
    "        # Reshape output to match target\n",
    "        output = output.view(-1, output.shape[2])     # (batch * seq_len, vocab_size)\n",
    "        target = dec_out.view(-1)                     # (batch * seq_len)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e52067-743f-4cb6-adf3-ac899905a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(encoder, decoder, input_tensor, tokenizer, max_len=30):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        _, hidden, cell = encoder(input_tensor.unsqueeze(0))  # (1, seq_len) ‚Üí batch\n",
    "\n",
    "        # Start token\n",
    "        decoder_input = torch.tensor([[tokenizer.word2idx[\"<SOS>\"]]])\n",
    "\n",
    "        output_words = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            predictions, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "            predicted_id = predictions.argmax(2)[:, -1].item()  # Take top word\n",
    "\n",
    "            if predicted_id == tokenizer.word2idx[\"<EOS>\"]:\n",
    "                break\n",
    "\n",
    "            output_words.append(tokenizer.idx2word.get(predicted_id, \"<UNK>\"))\n",
    "\n",
    "            decoder_input = torch.tensor([[predicted_id]])\n",
    "\n",
    "        return \" \".join(output_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ecbeaf-57a3-4186-8cb7-58ba6bec2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def summarize(encoder, decoder, doc, tokenizer, device, max_len=50):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Preprocess input\n",
    "    enc_input = tokenizer.encode(doc)\n",
    "    enc_input = torch.tensor(enc_input).unsqueeze(0).to(device)  # Shape: (1, seq_len)\n",
    "\n",
    "    # Encoder output\n",
    "    with torch.no_grad():\n",
    "        _, hidden, cell = encoder(enc_input)\n",
    "\n",
    "    # Start decoding with <SOS>\n",
    "    dec_input = torch.tensor([[tokenizer.word2idx[\"<SOS>\"]]]).to(device)  # Shape: (1, 1)\n",
    "\n",
    "    decoded_words = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = decoder(dec_input, hidden, cell)\n",
    "\n",
    "        # Get most probable token\n",
    "        pred_token = output.argmax(2).item()\n",
    "        if pred_token == tokenizer.word2idx[\"<EOS>\"]:\n",
    "            break\n",
    "\n",
    "        decoded_words.append(tokenizer.idx2word.get(pred_token, \"<UNK>\"))\n",
    "        dec_input = torch.tensor([[pred_token]]).to(device)\n",
    "\n",
    "    return \" \".join(decoded_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ddf55d-eb11-447d-936a-ede9c0015441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5.7740\n",
      "Epoch 2/10, Loss: 4.7009\n",
      "Epoch 3/10, Loss: 3.9460\n",
      "Epoch 4/10, Loss: 3.2158\n",
      "Epoch 5/10, Loss: 2.5714\n",
      "Epoch 6/10, Loss: 2.0198\n",
      "Epoch 7/10, Loss: 1.5903\n",
      "Epoch 8/10, Loss: 1.2504\n",
      "Epoch 9/10, Loss: 0.9624\n",
      "Epoch 10/10, Loss: 0.7223\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Training for multiple epochs\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_step(encoder, decoder, data, tokenizer,\n",
    "                      encoder_optimizer, decoder_optimizer,\n",
    "                      criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccbcff0e-151f-4b1d-b569-9d4bec7b2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generated Summary: <UNK> director oliver stone says he <UNK> indian cinema for `` being able to switch between <UNK> , <UNK> and tragedy at the same time '' .\n"
     ]
    }
   ],
   "source": [
    "test_paragraph = (\n",
    "    \"The Prime Minister addressed the nation on Tuesday evening, outlining the government‚Äôs plans to combat inflation \"\n",
    "    \"and stabilize the economy. In his speech, he announced a new fiscal stimulus package worth 10 billion dollars, \"\n",
    "    \"aimed at supporting small businesses and low-income families. The package includes tax cuts, subsidies, and increased \"\n",
    "    \"social welfare spending. Economists have welcomed the move but cautioned that its success will depend on timely implementation \"\n",
    "    \"and transparency.\"\n",
    ")\n",
    "\n",
    "summary = summarize(encoder, decoder, test_paragraph, tokenizer, device)\n",
    "print(\"üìù Generated Summary:\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41958f-6ba4-4afa-8cc9-0b252a5d693a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
